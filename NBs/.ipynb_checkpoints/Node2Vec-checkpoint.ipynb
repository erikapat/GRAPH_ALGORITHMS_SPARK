{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples in python ---> Node2Vec "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use node2vec algorithm to generate low dimensional representation of users to discover interesting user groups / clusters (e.g. popular professionals, satisfied students etc.) using only the available network structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['groups.csv',\n",
       " 'professionals.csv',\n",
       " 'tag_questions.csv',\n",
       " 'emails.csv',\n",
       " '.DS_Store',\n",
       " 'answers.csv',\n",
       " 'group_memberships.csv',\n",
       " 'tag_users.csv',\n",
       " 'matches.csv',\n",
       " 'answer_scores.csv',\n",
       " 'tags.csv',\n",
       " 'comments.csv',\n",
       " 'questions.csv',\n",
       " 'school_memberships.csv',\n",
       " 'question_scores.csv',\n",
       " 'students.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir(\"../social\")\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groups\n",
      "(49, 2)\n",
      "professionals\n",
      "(28152, 5)\n",
      "tag_questions\n",
      "(76553, 2)\n",
      "emails\n",
      "(1850101, 4)\n",
      "\n",
      "(0, 1)\n",
      "answers\n",
      "(51123, 5)\n",
      "group_memberships\n",
      "(1038, 2)\n",
      "tag_users\n",
      "(136663, 2)\n",
      "matches\n",
      "(4316275, 2)\n",
      "answer_scores\n",
      "(51138, 2)\n",
      "tags\n",
      "(16269, 2)\n",
      "comments\n",
      "(14966, 5)\n",
      "questions\n",
      "(23931, 5)\n",
      "school_memberships\n",
      "(5638, 2)\n",
      "question_scores\n",
      "(23928, 2)\n",
      "students\n",
      "(30971, 3)\n"
     ]
    }
   ],
   "source": [
    "data_parts = {}\n",
    "for file_name in files:\n",
    "    file_id = file_name.split(\".\")[0]\n",
    "    data_parts[file_id] = pd.read_csv(\"data/social/\" + file_name)\n",
    "    print(file_id)\n",
    "    print(data_parts[file_id].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_nodes(G, df, col, type_name):\n",
    "    \"\"\"Add entities to G from the 'col' column of the 'df' DataFrame. The new nodes are annotated with 'type_name' label.\"\"\"\n",
    "    nodes = list(df[~df[col].isnull()][col].unique())\n",
    "    G.add_nodes_from([(n,dict(type=type_name)) for n in nodes])\n",
    "    print(\"Nodes (%s,%s) were added\" % (col, type_name))\n",
    "    \n",
    "def add_links(G, df, col1, col2, type_name):\n",
    "    \"\"\"Add links to G from the 'df' DataFrame. The new edges are annotated with 'type_name' label.\"\"\"\n",
    "    df_tmp = df[(~df[col1].isnull()) & (~df[col2].isnull())]\n",
    "    links = list(zip(df_tmp[col1],df_tmp[col2]))\n",
    "    G.add_edges_from([(src, trg, dict(type=type_name)) for src, trg in links])\n",
    "    print(\"Edges (%s->%s,%s) were added\" % (col1, col2, type_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nodes\n",
    "The vertices of the knowledge graph consists of the following entities:\n",
    "\n",
    "* answers\n",
    "* questions\n",
    "* comments\n",
    "* students\n",
    "* professionals\n",
    "* industries\n",
    "* schools\n",
    "* tags\n",
    "* user groups\n",
    "* group types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes (answers_id,answer) were added\n",
      "Nodes (comments_id,comment) were added\n",
      "Nodes (groups_id,group) were added\n",
      "Nodes (groups_group_type,group_type) were added\n",
      "Nodes (professionals_id,professional) were added\n",
      "Nodes (professionals_industry,industry) were added\n",
      "Nodes (questions_id,question) were added\n",
      "Nodes (school_memberships_school_id,school) were added\n",
      "Nodes (students_id,student) were added\n",
      "Nodes (tags_tag_id,tag) were added\n"
     ]
    }
   ],
   "source": [
    "add_nodes(G, data_parts[\"answers\"], \"answers_id\", \"answer\")\n",
    "add_nodes(G, data_parts[\"comments\"], \"comments_id\", \"comment\")\n",
    "add_nodes(G, data_parts[\"groups\"], \"groups_id\", \"group\")\n",
    "add_nodes(G, data_parts[\"groups\"], \"groups_group_type\", \"group_type\")\n",
    "add_nodes(G, data_parts[\"professionals\"], \"professionals_id\", \"professional\")\n",
    "add_nodes(G, data_parts[\"professionals\"], \"professionals_industry\", \"industry\")\n",
    "add_nodes(G, data_parts[\"questions\"], \"questions_id\", \"question\")\n",
    "add_nodes(G, data_parts[\"school_memberships\"], \"school_memberships_school_id\", \"school\")\n",
    "add_nodes(G, data_parts[\"students\"], \"students_id\", \"student\")\n",
    "add_nodes(G, data_parts[\"tags\"], \"tags_tag_id\", \"tag\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edges (answers_id->answers_question_id,question) were added\n",
      "Edges (answers_id->answers_author_id,author) were added\n",
      "Edges (comments_id->comments_parent_content_id,parent_content) were added\n",
      "Edges (comments_id->comments_author_id,author) were added\n",
      "Edges (group_memberships_user_id->group_memberships_group_id,member) were added\n",
      "Edges (groups_id->groups_group_type,type) were added\n",
      "Edges (professionals_id->professionals_industry,type) were added\n",
      "Edges (questions_id->questions_author_id,author) were added\n",
      "Edges (school_memberships_user_id->school_memberships_school_id,member) were added\n",
      "Edges (tag_questions_question_id->tag_questions_tag_id,tag) were added\n",
      "Edges (tag_users_user_id->tag_users_tag_id,follow) were added\n"
     ]
    }
   ],
   "source": [
    "add_links(G, data_parts[\"answers\"], \"answers_id\", \"answers_question_id\", \"question\")\n",
    "add_links(G, data_parts[\"answers\"], \"answers_id\", \"answers_author_id\", \"author\")\n",
    "add_links(G, data_parts[\"comments\"], \"comments_id\", \"comments_parent_content_id\", \"parent_content\")\n",
    "add_links(G, data_parts[\"comments\"], \"comments_id\", \"comments_author_id\", \"author\")\n",
    "add_links(G, data_parts[\"group_memberships\"], \"group_memberships_user_id\", \"group_memberships_group_id\", \"member\")\n",
    "add_links(G, data_parts[\"groups\"], \"groups_id\", \"groups_group_type\", \"type\")\n",
    "add_links(G, data_parts[\"professionals\"], \"professionals_id\", \"professionals_industry\", \"type\")\n",
    "add_links(G, data_parts[\"questions\"], \"questions_id\", \"questions_author_id\", \"author\")\n",
    "add_links(G, data_parts[\"school_memberships\"], \"school_memberships_user_id\", \"school_memberships_school_id\", \"member\")\n",
    "add_links(G, data_parts[\"tag_questions\"], \"tag_questions_question_id\", \"tag_questions_tag_id\", \"tag\")\n",
    "add_links(G, data_parts[\"tag_users\"], \"tag_users_user_id\", \"tag_users_tag_id\", \"follow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location information\n",
    "Location information of users and professionals are preprocessed before I add it to the knowledge graph. I tried to extract city / state / country hierarchy from locations were it was provided. In this case I created different levels for locations: cities, states/regions and countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "students = data_parts[\"students\"]\n",
    "profs = data_parts[\"professionals\"]\n",
    "students = students[~students[\"students_location\"].isnull()]\n",
    "profs = profs[~profs[\"professionals_location\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs1 = list(students[\"students_location\"])\n",
    "locs2 = list(profs[\"professionals_location\"])\n",
    "locs = [loc.lower() for loc in locs1+locs2]\n",
    "locs_unique = list(set(locs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most common locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('new york, new york', 2650),\n",
       " ('bengaluru, karnataka, india', 1284),\n",
       " ('los angeles, california', 1280),\n",
       " ('boston, massachusetts', 1271),\n",
       " ('houston, texas', 1032),\n",
       " ('san francisco, california', 975),\n",
       " ('chicago, illinois', 920),\n",
       " ('california, california', 894),\n",
       " ('greater new york city area', 745),\n",
       " ('atlanta, georgia', 738)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = Counter(locs)\n",
    "cnt.most_common()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_edges = []\n",
    "new_nodes = []\n",
    "for loc in locs_unique:\n",
    "    loc_hierarchy = loc.split(\", \")\n",
    "    loc_nodes = [] # due to city name duplicates in the world\n",
    "    k = len(loc_hierarchy)\n",
    "    for i in range(k):\n",
    "        loc_nodes.append('_'.join(loc_hierarchy[i:]))\n",
    "    new_nodes += loc_nodes\n",
    "    loc_links = [(loc_nodes[i],loc_nodes[i+1], dict(type=\"location\"))  for i in range(k-1)]\n",
    "    new_edges += loc_links\n",
    "new_nodes = list(set(new_nodes))\n",
    "new_nodes = [(n, dict(type=\"location\")) for n in new_nodes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add location nodes to the graph\n",
    "* the 3 level of nodes are added\n",
    "* connections between cities -> regions, regions -> contires are added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7253 7160\n"
     ]
    }
   ],
   "source": [
    "G.add_nodes_from(new_nodes)\n",
    "G.add_edges_from(new_edges)\n",
    "print(len(new_edges), len(new_nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples:\n",
    "Locations that are immediate in-neighbors of entity United Kingdom (e.g.: England, Scotland etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('england_united kingdom', 'united kingdom'),\n",
       " ('leeds_united kingdom', 'united kingdom'),\n",
       " ('harrow_united kingdom', 'united kingdom'),\n",
       " ('edinburgh_united kingdom', 'united kingdom'),\n",
       " ('scotland_united kingdom', 'united kingdom')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(G.in_edges(\"united kingdom\"))[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Locations that are in-neighbors of entity England"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('windsor_england_united kingdom', 'england_united kingdom'),\n",
       " ('swindon_england_united kingdom', 'england_united kingdom'),\n",
       " ('kingston upon thames_england_united kingdom', 'england_united kingdom'),\n",
       " ('oxford_england_united kingdom', 'england_united kingdom'),\n",
       " ('luton_england_united kingdom', 'england_united kingdom')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(G.in_edges(\"england_united kingdom\"))[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Link users to the first level of locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erikapat/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/erikapat/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "students[\"students_location\"] = students[\"students_location\"].apply(lambda x: \"_\".join(x.lower().split(\", \")))\n",
    "profs[\"professionals_location\"] = profs[\"professionals_location\"].apply(lambda x: \"_\".join(x.lower().split(\", \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edges (students_id->students_location,location) were added\n",
      "Edges (professionals_id->professionals_location,location) were added\n"
     ]
    }
   ],
   "source": [
    "add_links(G, students, \"students_id\", \"students_location\", \"location\")\n",
    "add_links(G, profs, \"professionals_id\", \"professionals_location\", \"location\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean and encode knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_graph(G):\n",
    "    \"\"\"Encode the nodes of the network into integers\"\"\"\n",
    "    nodes = [(n,d.get(\"type\",None)) for n, d in G.nodes(data=True)]\n",
    "    nodes_df = pd.DataFrame(nodes, columns=[\"id\",\"type\"]).reset_index()\n",
    "    node2idx = dict(zip(nodes_df[\"id\"],nodes_df[\"index\"]))\n",
    "    edges = [(node2idx[src], node2idx[trg], d.get(\"type\",None)) for src, trg, d in G.edges(data=True)]\n",
    "    edges_df = pd.DataFrame(edges, columns=[\"src\",\"trg\",\"type\"])\n",
    "    return nodes_df, edges_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove isolated nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177890 461369\n",
      "174181 461369\n"
     ]
    }
   ],
   "source": [
    "print(G.number_of_nodes(), G.number_of_edges())\n",
    "G.remove_nodes_from(list(nx.isolates(G)))\n",
    "print(G.number_of_nodes(), G.number_of_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the nodes to have integer identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(174181, 461369)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_df, edges_df = encode_graph(G)\n",
    "len(nodes_df), len(edges_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Node information summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index                                id    type\n",
      "0      0  4e5f01128cae4f6d8fd697cec5dca60c  answer\n",
      "1      1  ada720538c014e9b8a6dceed09385ee3  answer\n",
      "2      2  eaa66ef919bc408ab5296237440e323f  answer\n",
      "3      3  1a6b3749d391486c9e371fbd1e605014  answer\n",
      "4      4  5229c514000446d582050f89ebd4e184  answer\n",
      "answer          51123\n",
      "student         29460\n",
      "professional    27819\n",
      "question        23931\n",
      "comment         14966\n",
      "tag             14404\n",
      "location         7160\n",
      "school           2706\n",
      "industry         2470\n",
      "group              49\n",
      "group_type          7\n",
      "Name: type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(nodes_df.head())\n",
    "print(nodes_df[\"type\"].value_counts())\n",
    "nodes_df.to_csv(\"knowledge_graph_nodes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edge information summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   src    trg      type\n",
      "0    0  96434  question\n",
      "1    0  68352    author\n",
      "2    1  96435  question\n",
      "3    1  83417    author\n",
      "4    2  96435  question\n",
      "follow            135907\n",
      "author             90020\n",
      "tag                76553\n",
      "location           60724\n",
      "question           51123\n",
      "type               25625\n",
      "parent_content     14966\n",
      "member              6451\n",
      "Name: type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(edges_df.head())\n",
    "print(edges_df[\"type\"].value_counts())\n",
    "edges_df[[\"src\",\"trg\"]].to_csv(\"knowledge_graph_edges.csv\", index=False, header=False, sep=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 96434), (0, 68352), (1, 96435), (1, 83417), (2, 96435)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_list = list(zip(edges_df[\"src\"],edges_df[\"trg\"]))\n",
    "edge_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(174181, 461369)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KG = nx.Graph(edge_list)\n",
    "KG.number_of_nodes(), KG.number_of_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** We will analyse only the greatest (weakly) connected component of our knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173933, 461225)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "largest_cc = max(nx.connected_components(KG), key=len)\n",
    "KG = nx.subgraph(KG, largest_cc)\n",
    "KG.number_of_nodes(), KG.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
